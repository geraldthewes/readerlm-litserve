# ReaderLM LitServe Configuration
# Copy this file to .env and customize as needed

# =============================================================================
# Model Configuration
# =============================================================================

# Hugging Face model name/path for the reader LM model
MODEL_NAME=jinaai/ReaderLM-v2

# Model revision (commit hash, tag, or branch) for reproducibility
# Use a specific commit hash for production deployments
MODEL_REVISION=main

# Model precision/dtype for inference
# Options: auto, float16, bfloat16, float32
# Use float16 for GPUs that don't support bfloat16 (e.g., T4)
# Use auto to let transformers choose based on model config
MODEL_DTYPE=auto

# Attention implementation for the model
# Options: eager, sdpa, flash_attention_2
# Use "eager" for better compatibility with float16 on older GPUs (Qwen2 recommendation)
# Use "sdpa" for PyTorch's native scaled dot-product attention
# Use "flash_attention_2" for Flash Attention 2 (requires compatible GPU)
ATTN_IMPLEMENTATION=eager

# =============================================================================
# Generation Parameters
# =============================================================================

# Maximum number of new tokens to generate
MAX_NEW_TOKENS=1024

# Sampling temperature (0 = deterministic, recommended for ReaderLM-v2)
TEMPERATURE=0

# Repetition penalty to reduce repetitive text (1.0 = no penalty)
REPETITION_PENALTY=1.08

# =============================================================================
# Server Configuration
# =============================================================================

# Port the server will listen on
SERVER_PORT=8000

# =============================================================================
# URL Fetching Configuration (for GET /{url} endpoint)
# =============================================================================

# Timeout for fetching external URLs in seconds
URL_FETCH_TIMEOUT=30

# User-Agent header sent when fetching URLs
URL_FETCH_USER_AGENT=ReaderLM/1.0

# Enable SSRF protection (block requests to private IPs)
# Set to "false" only in trusted environments
BLOCK_PRIVATE_IPS=true

# Domain allowlist (comma-separated, empty = allow all)
# Example: example.com,wikipedia.org
ALLOWED_DOMAINS=

# Domain blocklist (comma-separated, empty = block none)
# Example: localhost,internal.corp
BLOCKED_DOMAINS=

# =============================================================================
# Client Configuration (for client.py)
# =============================================================================

# Base URL of the server
SERVER_URL=http://127.0.0.1:8000

# Request timeout in seconds (model inference can be slow)
REQUEST_TIMEOUT=120
